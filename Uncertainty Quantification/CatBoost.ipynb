{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of UQ - Accuracy Rejection Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncertainty from Model 1, Model 1+2, Model 1+2+3, \n",
    "# instead of Model 1, Model 2, Model 3, \n",
    "# because n+1 Model always belong to Model n\n",
    "# in an additive manner\n",
    "\n",
    "# catboost delivers already laplace_smoothed_proba_predictions\n",
    "\n",
    "# 1/m Uncertainty\n",
    "def uncertainty(staged_preds):\n",
    "    \n",
    "    # function expects staged predictions from type generator\n",
    "    # and returns aleatoric, epistemic and total uncertainty\n",
    "    # for each prediction\n",
    "    \n",
    "    staged_preds = list(staged_preds)\n",
    "    \n",
    "    labels = [0,1] # labels are 0 or 1 for this task \n",
    "    num_trees = len(staged_preds) # number of trees\n",
    "    num_samples =  len(staged_preds[0]) # number of samples\n",
    "    print(num_trees)\n",
    "    print(num_samples)\n",
    "\n",
    "    # init uncertaintys\n",
    "    total = []\n",
    "    aleatoric = []\n",
    "    epistemic = []\n",
    "\n",
    "    # ALEATORIC UNCERTAINTY\n",
    "    for i in range(num_samples):\n",
    "        result = 0\n",
    "        previous_p = 0\n",
    "        \n",
    "        tree_probas = [el[0][0] for el in staged_preds][::-1]\n",
    "        tree_idx = num_trees - 1\n",
    "        for previous, current in zip(tree_probas, tree_probas[1:]):\n",
    "            if (previous != current):\n",
    "                break\n",
    "            tree_idx-=1\n",
    "        \n",
    "        for m in range(tree_idx):\n",
    "            for y in labels:\n",
    "                p = staged_preds[m][i][y]\n",
    "                result = result + (p * log(p,2))\n",
    "        \n",
    "        final = -(1/tree_idx) * result\n",
    "\n",
    "        aleatoric.append(final) \n",
    "\n",
    "    p_sum = 0\n",
    "    for i in range(num_samples):\n",
    "        result = 0\n",
    "        \n",
    "        tree_probas = [el[0][0] for el in staged_preds][::-1]\n",
    "        tree_idx = num_trees - 1\n",
    "        for previous, current in zip(tree_probas, tree_probas[1:]):\n",
    "            if (previous != current):\n",
    "                break\n",
    "            tree_idx-=1\n",
    "        \n",
    "        for y in labels:\n",
    "            p_sum = 0\n",
    "            for m in range(tree_idx):\n",
    "                \n",
    "                p = staged_preds[m][i][y]\n",
    "                p_sum = p + p_sum\n",
    "\n",
    "            p_avg_sum = ((1/tree_idx)* p_sum)\n",
    "            p_logged_avg_sum = p_avg_sum*log(p_avg_sum,2)\n",
    "            result = result + p_logged_avg_sum\n",
    "            \n",
    "        result = result *(-1)\n",
    "        total.append(result)\n",
    "        epistemic.append(result - aleatoric[i])\n",
    "    \n",
    "    return aleatoric, epistemic, total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_matrix(model, x_test, n_estimators, laplace_smoothing, log=False):\n",
    "    porb_matrix = [[[] for j in range(n_estimators)] for i in range(x_test.shape[0])]\n",
    "    for etree in range(n_estimators):\n",
    "        # populate the porb_matrix with the tree_prob\n",
    "        tree_prob = model.estimators_[etree].predict_proba(x_test)\n",
    "        if laplace_smoothing > 0:\n",
    "            leaf_index_array = model.estimators_[etree].apply(x_test)\n",
    "            for data_index, leaf_index in enumerate(leaf_index_array):\n",
    "                leaf_values = model.estimators_[etree].tree_.value[leaf_index]\n",
    "                leaf_samples = np.array(leaf_values).sum()\n",
    "                for i,v in enumerate(leaf_values[0]):\n",
    "                    tmp = (v + laplace_smoothing) / (leaf_samples + (len(leaf_values[0]) * laplace_smoothing))\n",
    "                    # print(f\">>>>>>>>>>>>>>> {tmp}  data_index {data_index} prob_index {i} v {v} leaf_samples {leaf_samples}\")\n",
    "                    tree_prob[data_index][i] = (v + laplace_smoothing) / (leaf_samples + (len(leaf_values[0]) * laplace_smoothing))\n",
    "                # exit()\n",
    "\n",
    "        for data_index, data_prob in enumerate(tree_prob):\n",
    "            porb_matrix[data_index][etree] = list(data_prob)\n",
    "\n",
    "        if log:\n",
    "            print(f\"----------------------------------------[{etree}]\")\n",
    "            print(f\"class {model.estimators_[etree].predict(x_test)}  prob \\n{tree_prob}\")\n",
    "    return porb_matrix\n",
    "\n",
    "def uncertainty_estimate(probs): # three dimentianl array with d1 as datapoints, (d2) the rows as samples and (d3) the columns as probability for each class\n",
    "    p = np.array(probs)\n",
    "    entropy = -p*np.ma.log10(p)\n",
    "    entropy = entropy.filled(0)\n",
    "    a = np.sum(entropy, axis=1)\n",
    "    a = np.sum(a, axis=1) / entropy.shape[1]\n",
    "    p_m = np.mean(p, axis=1)\n",
    "    total = -np.sum(p_m*np.ma.log10(p_m), axis=1)\n",
    "    total = total.filled(0)\n",
    "    e = total - a\n",
    "    return total, e, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SPECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('SPECT .train', delimiter=',', header=None)\n",
    "test = pd.read_csv('SPECT .test', delimiter=',',header=None)\n",
    "data = pd.concat([train,test]).reset_index(drop=True)\n",
    "x = data.drop(0, axis=1)\n",
    "y = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8518518518518519\n"
     ]
    }
   ],
   "source": [
    "test_size=0.3\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size,shuffle=True)\n",
    "x_train, x_test, y_train, y_test = x_train.copy(), x_test.copy(), y_train.copy(), y_test.copy()\n",
    "model = CatBoostClassifier(iterations=10,\n",
    "                               learning_rate=0.5,\n",
    "                               depth=10,\n",
    "                              cat_features=x_train.columns-1,\n",
    "                              silent=True)\n",
    "# Fit model\n",
    "model.fit(x_train, y_train)\n",
    "# Get predicted classes\n",
    "preds_class = model.predict(x_test)\n",
    "# Get predicted probabilities for each class\n",
    "preds_proba = model.predict_proba(x_test)\n",
    "\n",
    "print(\"Accuracy = {}\".format(accuracy_score(y_test, preds_class)))\n",
    "\n",
    "staged_preds = model.staged_predict(x_test,\n",
    "               prediction_type='Probability',\n",
    "               ntree_start=0, \n",
    "               ntree_end=10)\n",
    "\n",
    "\n",
    "model_probas = list(staged_preds)\n",
    "model_probas_transposed = []\n",
    "for i in range(len(model_probas[0])):\n",
    "    model_probas_transposed.append([el[i] for el in model_probas])\n",
    "\n",
    "total_uncertainty, epistemic_uncertainty, aleatoric_uncertainty = uncertainty_estimate(np.array(model_probas_transposed))\n",
    "\n",
    "p = np.array(model_probas_transposed)\n",
    "\n",
    "model_unique = []\n",
    "for i in range(len(p)):\n",
    "    model_unique.append(np.unique(p[i], axis=0))\n",
    "\n",
    "entropy = -p*np.ma.log10(p)\n",
    "entropy = entropy.filled(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8148148148148148\n",
      "Accuracy = 0.7160493827160493\n",
      "Accuracy = 0.8518518518518519\n",
      "Accuracy = 0.8765432098765432\n",
      "Accuracy = 0.7901234567901234\n",
      "Accuracy = 0.8271604938271605\n",
      "Accuracy = 0.8888888888888888\n",
      "Accuracy = 0.7777777777777778\n",
      "Accuracy = 0.7654320987654321\n",
      "Accuracy = 0.8148148148148148\n",
      "Accuracy = 0.7654320987654321\n",
      "Accuracy = 0.8148148148148148\n",
      "Accuracy = 0.8024691358024691\n",
      "Accuracy = 0.7901234567901234\n",
      "Accuracy = 0.8395061728395061\n",
      "Accuracy = 0.8395061728395061\n",
      "Accuracy = 0.8395061728395061\n",
      "Accuracy = 0.8148148148148148\n",
      "Accuracy = 0.7777777777777778\n",
      "Accuracy = 0.8888888888888888\n",
      "Accuracy = 0.8765432098765432\n",
      "Accuracy = 0.8395061728395061\n",
      "Accuracy = 0.8395061728395061\n",
      "Accuracy = 0.8024691358024691\n",
      "Accuracy = 0.8148148148148148\n",
      "Accuracy = 0.8518518518518519\n",
      "Accuracy = 0.7654320987654321\n",
      "Accuracy = 0.8271604938271605\n",
      "Accuracy = 0.7901234567901234\n",
      "Accuracy = 0.8641975308641975\n",
      "Accuracy = 0.8518518518518519\n",
      "Accuracy = 0.8518518518518519\n",
      "Accuracy = 0.8395061728395061\n",
      "Accuracy = 0.8641975308641975\n",
      "Accuracy = 0.8024691358024691\n",
      "Accuracy = 0.7777777777777778\n",
      "Accuracy = 0.8641975308641975\n",
      "Accuracy = 0.8148148148148148\n",
      "Accuracy = 0.8395061728395061\n",
      "Accuracy = 0.8148148148148148\n",
      "Accuracy = 0.8395061728395061\n",
      "Accuracy = 0.8148148148148148\n",
      "Accuracy = 0.8148148148148148\n",
      "Accuracy = 0.8641975308641975\n",
      "Accuracy = 0.8765432098765432\n",
      "Accuracy = 0.8148148148148148\n",
      "Accuracy = 0.7777777777777778\n",
      "Accuracy = 0.8765432098765432\n",
      "Accuracy = 0.8148148148148148\n",
      "Accuracy = 0.7901234567901234\n",
      "Accuracy = 0.8148148148148148\n",
      "Accuracy = 0.8271604938271605\n",
      "Accuracy = 0.8024691358024691\n",
      "Accuracy = 0.8148148148148148\n",
      "Accuracy = 0.7901234567901234\n",
      "Accuracy = 0.8395061728395061\n",
      "Accuracy = 0.8395061728395061\n",
      "Accuracy = 0.7530864197530864\n",
      "Accuracy = 0.8024691358024691\n",
      "Accuracy = 0.8395061728395061\n",
      "Accuracy = 0.7901234567901234\n",
      "Accuracy = 0.8765432098765432\n",
      "Accuracy = 0.8765432098765432\n",
      "Accuracy = 0.8148148148148148\n",
      "Accuracy = 0.8148148148148148\n",
      "Accuracy = 0.8765432098765432\n",
      "Accuracy = 0.8765432098765432\n",
      "Accuracy = 0.8395061728395061\n",
      "Accuracy = 0.8148148148148148\n",
      "Accuracy = 0.7777777777777778\n",
      "Accuracy = 0.8148148148148148\n",
      "Accuracy = 0.8395061728395061\n",
      "Accuracy = 0.8271604938271605\n",
      "Accuracy = 0.8395061728395061\n",
      "Accuracy = 0.7530864197530864\n",
      "Accuracy = 0.8271604938271605\n",
      "Accuracy = 0.7901234567901234\n",
      "Accuracy = 0.8271604938271605\n",
      "Accuracy = 0.7777777777777778\n",
      "Accuracy = 0.7530864197530864\n",
      "Accuracy = 0.8271604938271605\n",
      "Accuracy = 0.7901234567901234\n",
      "Accuracy = 0.8271604938271605\n",
      "Accuracy = 0.8518518518518519\n",
      "Accuracy = 0.8395061728395061\n",
      "Accuracy = 0.8148148148148148\n",
      "Accuracy = 0.8395061728395061\n",
      "Accuracy = 0.7777777777777778\n",
      "Accuracy = 0.8518518518518519\n",
      "Accuracy = 0.8518518518518519\n",
      "Accuracy = 0.7037037037037037\n",
      "Accuracy = 0.8888888888888888\n",
      "Accuracy = 0.7654320987654321\n",
      "Accuracy = 0.8395061728395061\n",
      "Accuracy = 0.7777777777777778\n",
      "Accuracy = 0.7407407407407407\n",
      "Accuracy = 0.8888888888888888\n",
      "Accuracy = 0.8395061728395061\n",
      "Accuracy = 0.8148148148148148\n",
      "Accuracy = 0.8765432098765432\n"
     ]
    }
   ],
   "source": [
    "ARC_eU_list, ARC_aU_list, ARC_random_list = [],[],[]\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    test_size=0.3\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size,shuffle=True)\n",
    "    x_train, x_test, y_train, y_test = x_train.copy(), x_test.copy(), y_train.copy(), y_test.copy()\n",
    "\n",
    "    model = CatBoostClassifier(iterations=10,\n",
    "                               learning_rate=0.5,\n",
    "                               depth=10,\n",
    "                              cat_features=x_train.columns-1,\n",
    "                              silent=True)\n",
    "    # Fit model\n",
    "    model.fit(x_train, y_train)\n",
    "    # Get predicted classes\n",
    "    preds_class = model.predict(x_test)\n",
    "    # Get predicted probabilities for each class\n",
    "    preds_proba = model.predict_proba(x_test)\n",
    "\n",
    "    print(\"Accuracy = {}\".format(accuracy_score(y_test, preds_class)))\n",
    "\n",
    "    staged_preds = model.staged_predict(x_test,\n",
    "                   prediction_type='Probability',\n",
    "                   ntree_start=0, \n",
    "                   ntree_end=10)\n",
    "\n",
    "\n",
    "    model_probas = list(staged_preds)\n",
    "    model_probas_transposed = []\n",
    "    for i in range(len(model_probas[0])):\n",
    "        model_probas_transposed.append([el[i] for el in model_probas])\n",
    "\n",
    "    total_uncertainty, epistemic_uncertainty, aleatoric_uncertainty = uncertainty_estimate(np.array(model_probas_transposed))\n",
    "    \n",
    "    x_test['a']=aleatoric_uncertainty\n",
    "    x_test['e']=epistemic_uncertainty\n",
    "\n",
    "    num_rows = x_test.shape[0]\n",
    "    discard_count = 0\n",
    "    eU = x_test.sort_values('e', ascending=True)\n",
    "    aU = x_test.sort_values('a', ascending=True)\n",
    "\n",
    "    ARC_eU = ARC_aU = ARC_random = [preds_class]\n",
    "\n",
    "    i = 0.05\n",
    "    while i < 1:\n",
    "        discard_count = int (num_rows*i)\n",
    "        eU_samples = eU.iloc[:-discard_count,0:22]\n",
    "        aU_samples = aU.iloc[:-discard_count,0:22]\n",
    "        random_samples = x_test.sample((num_rows-discard_count))\n",
    "        preds_class_eU = model.predict(eU_samples)\n",
    "        preds_class_aU = model.predict(aU_samples)\n",
    "        preds_class_random = model.predict(random_samples)\n",
    "        accuracy_eu = accuracy_score(y_test[eU_samples.index], preds_class_eU)\n",
    "        accuracy_au = accuracy_score(y_test[aU_samples.index], preds_class_aU)\n",
    "        accuracy_random = accuracy_score(y_test[random_samples.index], preds_class_random)\n",
    "        ARC_eU.append(accuracy_eu)\n",
    "        ARC_aU.append(accuracy_au)\n",
    "        ARC_random.append(accuracy_random)\n",
    "        i+=0.05\n",
    "    \n",
    "    ARC_eU_list.append(ARC_eU)\n",
    "    ARC_aU_list.append(ARC_aU)\n",
    "    ARC_random_list.append(ARC_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARC_eU_mean, ARC_aU_mean, ARC_random_mean = [],[],[]\n",
    "for i in range(len(ARC_eU_list[0])):\n",
    "    ARC_eU_mean.append(np.array([el[i] for el in ARC_eU_list]).mean())\n",
    "    ARC_aU_mean.append(np.array([el[i] for el in ARC_aU_list]).mean())\n",
    "    ARC_random_mean.append(np.array([el[i] for el in ARC_random_list]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject   E    A    R \n",
      "0.05:  0.83 0.83 0.82 \n",
      "0.10:  0.83 0.84 0.82 \n",
      "0.15:  0.84 0.85 0.82 \n",
      "0.20:  0.84 0.86 0.82 \n",
      "0.25:  0.84 0.87 0.82 \n",
      "0.30:  0.85 0.88 0.82 \n",
      "0.35:  0.85 0.90 0.83 \n",
      "0.40:  0.85 0.91 0.83 \n",
      "0.45:  0.86 0.92 0.83 \n",
      "0.50:  0.86 0.93 0.82 \n",
      "0.55:  0.86 0.93 0.82 \n",
      "0.60:  0.86 0.94 0.82 \n",
      "0.65:  0.87 0.94 0.82 \n",
      "0.70:  0.87 0.95 0.84 \n",
      "0.75:  0.87 0.95 0.82 \n",
      "0.80:  0.87 0.96 0.82 \n",
      "0.85:  0.88 0.97 0.84 \n",
      "0.90:  0.88 0.98 0.80 \n",
      "0.95:  0.88 0.98 0.85 \n"
     ]
    }
   ],
   "source": [
    "print('Reject   E    A    R ')\n",
    "i = 0.05\n",
    "for e,a,r in zip(ARC_eU_mean,ARC_aU_mean,ARC_random_mean):\n",
    "    print(f'{i:.2f}:  {e:.2f} {a:.2f} {r:.2f} ')\n",
    "    i +=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8297402597402599,\n",
       " 0.8335616438356166,\n",
       " 0.8373913043478263,\n",
       " 0.8403076923076922,\n",
       " 0.8432786885245902,\n",
       " 0.8450877192982454,\n",
       " 0.8471698113207549,\n",
       " 0.8530612244897959,\n",
       " 0.8588888888888888,\n",
       " 0.8607317073170733,\n",
       " 0.8605405405405406,\n",
       " 0.8627272727272727,\n",
       " 0.8651724137931035,\n",
       " 0.8688000000000001,\n",
       " 0.8719047619047617,\n",
       " 0.8705882352941176,\n",
       " 0.8753846153846154,\n",
       " 0.8766666666666666,\n",
       " 0.88]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARC_eU_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
